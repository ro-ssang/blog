# 4장 애플리케이션 소스 코드에서 도커 이미지까지

## 멀티 스테이지 Dockerfile 스크립트

* 어떤 운영체제를 사용하든지 로컬 컴퓨터에 어떤 도구를 설치했는지와 상관없이, 개발 및 애플리케이션 패키징에 필요한 모든 도구들을 Dockerfile 스크립트에 작성하여 개발 도구에 대한 **유지 보수에 대한 오버헤드를 줄일 수 있고 표준화를 이룰 수 있다**.
* **멀티 스테이지 빌드의 각 단계는 자신만의 캐시를 따로 갖으며**, 이미지 빌드 중에 해당되는 이미지 캐시 레이어를 찾지 못한다면 남은 인스트럭션이 모두 실행되지만, 그 범위가 해당 단계 안으로 국한되어 Dockerfile 스크립트를 세심하게 최적화해서 작성한다면 캐시 재사용을 통해 빌드 단계에서 **성능 향상**을 이룰 수 있다.
* 멀티 스테이지 Dockerfile 스크립트를 통해 빌드 과정을 세밀하게 조정하며 최종 산출물인 **이미지를 가능한 작게 유지**할 수 있다.

```dockerfile
FROM diamol/base AS build-stage
RUN echo "Building..." > /build.txt

FROM diamol/base AS test-stage
COPY --from=build-stage /build.txt .
RUN echo "Testing..." >> /build.txt

FROM diamol/base
COPY --from=test-stage /build.txt .
CMD ["cat", "/build.txt"]
```

| 인스트럭션               | 내용                                                         |
| ------------------------ | ------------------------------------------------------------ |
| `COPY --from=stage-name` | 앞선 빌드 단계의 파일 시스템에 있는 파일 혹은 디렉터리를 복사, `[원본경로] [복사경로]` 형식을 따름 |
| `RUN`                    | 빌드 중에 컨테이너 안에서 명령을 실행한 다음 그 결과를 이미지 레이어에 저장 |



## 애플리케이션 빌드 실전 예제: 자바 소스 코드

```dockerfile
FROM diamol/maven AS builder

WORKDIR /usr/src/iotd
COPY pom.xml .
RUN mvn -B dependency:go-offline

COPY . .
RUN mvn package

# app
FROM diamol/openjdk

WORKDIR /app
COPY --from=builder /usr/src/iotd/target/iotd-service-0.1.0.jar .

EXPOSE 80
ENTRYPOINT ["java", "-jar", "/app/iotd-service-0.1.0.jar"]
```

* builder 단계의 이미지에서는 메이븐과 OpenJDK를 포함하고 있고 의존 모듈을 내려 받는 과정을 분리하여 이미지 레이어 캐시를 활용할 수 있도록 하였고, 최종 결과물로 JAR 포맷으로 패키징된 자바 애플리케이션을 만든다.
* builder 단계가 수행난 다음 단계에서는 자바 11만 포함하고 있고, builder 단계에서 만든 JAR 파일을 복사하여 실행한다.

| 인스트럭션   | 내용                                                         |
| ------------ | ------------------------------------------------------------ |
| `EXPOSE`     | 컨테이너의 특정 포트를 외부로 공개                           |
| `ENTRYPOINT` | `CMD` 인스트럭션과 마찬가지로 컨테이너를 실행했을 때 실행할 명령어를 지정 |

> 💡 `EXPOSE` 와 `--publish` , `-p` 차이점
>
> `EXPOSE` 컨테이너의 포트를 외부로 공개하며 컨테이너를 실행시킬 때, `--publish` , `-p` 을 이용하여 호스트 머신과 컨테이너의 포트를 맵핑하지 않고 `docker container run -P` 라고 실행하면 호스트 머신의 포트가 랜덤하게 배정되어 실행된다.

> 💡 `CMD` 와 `ENTRYPOINT` 차이점
>
> 컨테이너를 실행할 때, `docker container run <IMAGE ID> echo 'hi'` 라고 한다면 `CMD` 인스트럭션으로 만들어진 이미지의 `CMD` 명령어는 무시되고 `echo 'hi'`  만 실행되지만, `ENTRYPOINT` 인스트럭션으로 만든 이미지는 `ENTRYPOINT` 인스트럭션이 실행되고 추가로 지정한 `echo 'hi'` 라는 명령어가 실행된다.



## 애플리케이션 빌드 실전 예제: Node.js 소스 코드

```dockerfile
FROM diamol/node AS builder

WORKDIR /src
COPY src/package.json .
RUN npm install

# app
FROM diamol/node

EXPOSE 80
CMD ["node", "server.js"]

WORKDIR /app
COPY --from=builder /src/node_modules/ /app/node_modules/
COPY src/ .
```



## 애플리케이션 빌드 실전 예제: Go 소스 코드

```dockerfile
FROM diamol/golang AS builder

COPY main.go .
RUN go build -o /server

# app
FROM diamol/base
ENV IMAGE_API_URL="http://iotd/image" \
    ACCESS_API_URL="http://accesslog/access-log"

CMD ["/web/server"]

WORKDIR /web
COPY index.html .
COPY --from=builder /server .
RUN chmod +x server
```



## 생각해보기

- [x] 멀티스테이지를 사용하면 이미지 레이어 캐시가 스테이지 별로 구분 될지?
- [x] 노드에서 빌드 및 태스트 스테이지로 나눈다면 어떻게 나눌 수 있을지?
- [x] java 애플리케이션 예제에서 expose랑 entrypoint가 위로 올라 와야지 캐시를 더 활용할 수 있지 않을까?
- [x] java 애플리케이션 예제에서 빌더 단계에서 한번에 파일들을 복사해 오는게 효율적이지 않을까? 굳이 나누는 이유?
- [x] entrypoint와 cmd 인스트럭션의 차이점
- [x] expose의 의미?
- [x] 하나의 docker 네트워크로 묶어주는데 물리적 서버가 떨어져 있으면 어떻게 해야할까?
- [x] go 애플리케이션에서 환경변수가 어떻게 동작하는지 확인하기
- [x] go 애플리케이션에서 expose가 없음
- [x] 개발용 혹은 배포용 이미지를 어떻게 나눌 수 있을까?
