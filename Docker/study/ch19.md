# 19장 도커를 이용한 로그 생성 및 관리

## 표준 에러 스트림과 표준 출력 스트림

### 도커에서 컨테이너 로그를 수집하는 방법

도커에서 컨테이너 로그를 수집하려면 **컨테이너를 시작할 때** 로그를 수집하고자 하는 애플리케이션 프로세스를 **포어그라운드로 시작**해야 하며, 실행된 프로세스에서 생성한 로그 엔트리는 **표준 출력(stdout) 및 표준 오류(stderr) 스트림으로 출력**하도록 해야한다.

도커는 터미널 세션과 분리된(detached) 컨테이너와 종료된 컨테이너의 로그를 수집할 수 있도록 **로그를 JSON 파일로도 저장**한다. 이 JSON 파일은 도커가 직접 컨테이너와 동일한 생애주기를 갖도록 관리한다. 즉, 컨테이너가 제거되면 로그 파일도 함께 삭제된다.

```sh
# 컨테이너 로그 파일 경로 확인
docker container inspect --format='{{.LogPath}}' timecheck
```

> ⚠️ 단, 도커 데스크톱으로 리눅스를 실행 중이라면, 도커 엔진이 별도로 관리되는 가상 머신 안에서 실행되므로, 위 명령에서 출력된 로그의 파일 경로는 이 가상 머신 내부의 경로이므로 이 파일에 직접 접근할 수 없다. 하지만 리눅스 환경에서 도커 커뮤니티 에디션을 사용하거나 윈도 컨테이너를 실행했다면, 로그 파일 경로는 로컬 컴퓨터 내부의 경로이므로 로그 파일에 직접 접근할 수 있다.

매우 많은 양의 로그를 생산하는 컨테이너가 있고 이 로그의 일정 기간 분량을 관리할 수 있는 파일 구조로 유지해야 한다면 JSON 형식을 고려하는 것이 좋다. 또한 컨테이너마다 로그 파일에 롤링을 적용하거나, 최대 파일 개수 및 파일 크기를 설정할 수도 있다.

```sh
# 로그 설정을 변경해 애플리케이션 실행
docker container run -d --name timecheck2 --log-opt max-size=5k --log-out max-file=3 -e Timer__IntervalSeconds=1 diamol/ch15-timecheck:3.0
```



## 다른 곳으로 출력된 로그를 stdout 스트림에 전달하기

애플리케이션을 컨테이너화하더라도 출력 스트림으로 아무 내용도 출력하지 않는 애플리케이션은 표준 로그 모델을 적용하기 어렵다. 다음 예시들은 모두 컨테이너 시작 프로세스에서 출력되는 로그가 없으므로 도커가 로그를 수집하지 못한다.

* 윈도 서비스 또는 리눅스 데몬 형태로 동작하는 애플리케이션은 실제 애플리케이션 프로세스가 컨테이너 시작 프로세스와 일치하지 않는다.
* 리눅스의 syslog나 윈도의 이벤트 로그처럼 별도의 로그 프레임워크를 경유해 다룬 곳에 로그를 생산하는 경우도 있다.

이런 애플리케이션에서 컨테이너 로그를 수집하려면, 로그 파일의 내용을 읽어 표준 출력으로 내보내 주는 별도의 셸 스크립트 또는 간단한 유틸리티 프로세스를 컨테이너 시작 시퀀스에서 마지막으로 실행하면 된다.

이런 방법에도 다음과 같은 단점이 존재한다.

* 로그 전달용 유틸리티는 포어그라운드로 동작하므로 이 프로세스가 종료되면 애플리케이션과 함께 컨테이너까지 종료되기 때문에 유틸리티는 오류를 일으키지 않도록 세심하게 작성해야 한다.
* 애플리케이션이 오류로 종료돼도 포어그라운드로 동작 중인 로그 전달 유틸리티가 계속 실행 중이므로 컨테이너도 계속 실행되기 때문에 헬스 체크를 적용하지 않으면 이상 상태를 감지할 수 없다.
* 다량의 로그를 생성하는 애플리케이션이라면, 컨테이너 파일 시스템과 도커 호스트 컴퓨터의 디스크 용량을 많이 점유한다.

이런 단점에도 불구하고 백그라운드로 동작하는 애플리케이션, 로그 설정에 개입할 여지가 없는 상황이라면 앞에서 설명한 단점을 모두 감수하고 다른 컨테이너와 같이 로그를 수집하는 편이 더 낫다.

```dockerfile
FROM diamol/dotnet-sdk as builder
WORKDIR /src
COPY src/TimeCheck.csproj .
RUN dotnet restore
COPY src /src
RUN dotnet publish -c Release -o /out TimeCheck.csproj

# tail utility
FROM diamol/dotnet-sdk as utility
WORKDIR /utility
COPY utility/Tail.csproj .
RUN dotnet restore
COPY utility /utility
RUN dotnet publish -c Release -o /out Tail.csproj

# app image
FROM diamol/dotnet-runtime AS base

ARG BUILD_NUMBER=0
ARG BUILD_TAG=local

LABEL version="5.0"
LABEL build_number=${BUILD_NUMBER}
LABEL build_tag=${BUILD_TAG}

ENV Application__Version="5.0" \
    DOTNET_USE_POLLING_FILE_WATCHER="true"

WORKDIR /logs
RUN echo Init > timecheck.log

WORKDIR /app
COPY --from=builder /out/ .
COPY --from=utility /out/ .

# windows
FROM base AS windows
CMD start /B dotnet TimeCheck.dll && dotnet Tail.dll /logs timecheck.log

# linux
FROM base AS linux
CMD dotnet TimeCheck.dll & dotnet Tail.dll /logs timecheck.log
```

위 예시의 닷넷 유틸리티 tail은 로그 파일을 감시하다가 새로운 내용이 추가되면 그 때마다 해당 내용을 stdout 스트림으로 전달해 컨테이너 로그로 수집되도록 하는 역할을 한다. 이 방법의 단점은 로그를 전달하는 과정과 함께 로그가 두 번 저장되면서 연산 능력과 디스크 용량이 낭비된다는 점이다.

위 예시에서 리눅스 표준 명령인 tail을 사용해도 무방하지만, 윈도에는 tail을 대체할 수 있는 명령이 없으므로 어떤 유형의 싱크도 stdout 스트림에 연결할 수 있는 커스텀 유틸리티가 유연성 면에서 더 뛰어나다.



## 컨테이너 로그 수집 및 포워딩하기

모든 이미지에서 컨테이너 로그를 수집할 수 있는 준비가 끝났다면, 모든 컨테이너에서 수집된 로그를 종합할 수 있는 도커의 플러그인 로깅 시스템을 적용할 수 있다.

### fluentd

fluentd는 가장 널리 쓰이는 오픈소스 로깅 시스템으로써 통합 로깅 계층이다. 통합 로깅 계층은 다양한 곳에서 생성되는 로그를 모으고, 필터링과 가공을 거쳐 다시 여러 대상으로 수집된 로그를 포워딩하는 역할을 한다. fluentd는 성숙도가 높으면서도 매우 유연한 시스템인데, fluentd를 컨테이너로 실행하고 다른 컨테이너에서 일반적인 JSON 파일 대신 fluentd 로깅 드라이버를 사용하도록 하면, 이들 컨테이너에서 생성되는 로그가 fluentd로 전송된다.

```sh
# 설정 파일과 표준 포트를 적용한 fluentd 컨테이너를 실행
docker container run -d -p 24224:24224 --name fluentd -v "$(pwd)/conf:/fluentd/etc" -e FLUENTD_CONF=stdout.conf diamol/fluentd

# fluentd 로그 드라이버가 설정된 timecheck 애플리케이션 컨테이너 실행
docker container run -d --log-driver=fluentd --name timecheck5 diamol/ch19-timecheck:5.0

# timecheck 컨테이너의 로그를 확인 (fluentd 로깅 드라이버를 사용하면 애플리케이션 컨테이너에서 로그를 볼 수 없다.)
docker container logs timecheck5

# fluentd 컨테이너의 로그를 확인
docker container logs --tail 1 fluentd
```

fluentd는 전체 애플리 케이션의 로그를 수집하는 역할을 하므로 수집한 로그에 자체 메타데이터를 추가해 저장하는데, 이 메타데이터에는 컨테이너 ID와 이름 등이 포함된다.

fluentd에서 로그에 태그를 추가하려면 간단히 로깅 드라이버에 설정을 추가하면 된다. 고정된 이름을 사용하거나 별도의 식별자를 외부에서 주입할 수 있는데, 애플리케이션과 컴포넌트, 정확한 버전까지 한눈에 알 수 있는 식별자를 선택하는 것이 좋다. 여기서는 모든 로그에서 태그 필드에 포함된 애플리케이션 이름, 서비스 이름, 이미지 이름을 별도의 필드로 분리해 향후 키바나에서 로그를 쉽게 필터링할 수 있도록 했다.

```yaml
version: "3.7"

services:
  accesslog:
    image: diamol/ch18-access-log
    networks:
      - iotd-net
    logging:
      driver: "fluentd"
      options:
        tag: "gallery.access-log.{{.ImageName}}"

  iotd:
    image: diamol/ch18-image-of-the-day
    networks:
      - iotd-net
    logging:
      driver: "fluentd"
      options:
        tag: "gallery.iotd.{{.ImageName}}"

  image-gallery:
    image: diamol/ch18-image-gallery
    ports:
      - "8010:80"
    depends_on:
      - accesslog
      - iotd
    networks:
      - iotd-net
    logging:
      driver: "fluentd"
      options:
        tag: "gallery.image-gallery.{{.ImageName}}"

networks:
  iotd-net:
```

수집된 로그는 대개 중앙 데이터 스토어로 전송되는데, NoSQL 문서 데이터베이스로 유명한 일래스틱서치 등이 로그 데이터 스토어로 널리 쓰인다. 또한 일랙스틱서치에 로그를 저장하고 로그 검색 UI 및 기능을 제공하는 키바나를 함께 사용하는 것이 일반적이다.

키바나를 사용하면 모든 컨테이너의 로그 중에서 특정 키워드를 포함하는 로그를 검색하거나 시간 등을 기준으로 로그를 필터링할 수 있으며, 애플리케이션별 로그 건수나 오류 로구 건수 등을 대시보드로 한눈에 파악할 수 있다.

일래스틱서치는 수평 확장이 매우 용이하므로 운영 환경에서 생성되는 대량의 로그를 처리하는 데 적합하다.

도커에는 fluentd 외에도 다양한 로깅드라이버가 있는데, 오픈 소스 도구로는 그레이로그(Graylog), 상용 도구로는 스플렁크(Splunk) 등이 있다.

### 정리

* 중앙 집중식 로그 모델에 검색 가능한 데이터 스토어, 사용자 친화적인 검색 UI를 갖추는 것은 운영 환경에 필수적이다.
* fluentd이외에도 오픈 소스 도구로는 그레이로그(Graylog), 상용 도구로는 스플렁크(Splunk) 등이 있다.
* 앞서 설명했듯이 기본 로깅 드라이버는 도거 엔진 설정으로 지정하지만, 애플리케이션 매니페스트에서 로깅 시스템을 명시적으로 지정하는 편이 더 낫다.
* 로깅 시스템에 대한 경험이 많지 않다면 fluentd를 추천할 만하다.
	* 개발용 단일 컴퓨터에서 운영용 클러스터로 어렵지 않게 확장할 수도 있다.
	* 어떤 환경에서든 동일한 방법으로 사용할 수 있다.
	* 로그에 메타데이터를 추가하거나 필터를 적용해 로그 유형별로 저장소를 달리할 수도 있다.



## 로그 출력 및 로그 컬렉션 관리하기

로그는 대량의 불필요한 데이터 저장과 문제 진단에 필요한 정보 확보 사이를 오가는 줄타기와 같은데, 도커의 유연한 로깅 모델을 이용하면 컨테이너에는 상세한 로그를 생성하면서 로그를 저장할 때는 필터링을 적용할 수 있어 균형을 잡는 데 어느 정도 도움이 된다. 만약 더욱 상세한 로그가 필요할 때는 애플리케이션 설정에 손댈 필요 없이 fluentd 필터 설정만 수정하면 된다.

로그 필터링은 fluentd 설정 파일에서 정의할 수 있다.

```
<match gallery.access-log.**>
  @type copy
  <store>
    @type stdout
  </store>
</match>
<match gallery.**>
  @type copy
  <store>
    @type elasticsearch
    ...
```

`match` 블록은 해당 블록의 필터 파라미터와 태그가 일치하는 로그를 어떻게 처리할 것인지를 정의한다. 일치 여부를 판단하는 태그 필드는 로깅 드라이버 설정에 지정된 것이다. 위 로그 설정을 적용하면 `access-log` 에서 생성된 로그는 첫 번째 `match` 블록과 태그가 일치하므로일래스틱서치로 전달되는 대신 fluentd 컨테이너 로그에서만 볼 수 있다.

이 방법은 애플리케이션의 핵심 로그와 '있으면 좋은 정도'의 로그를 분리하는 데 유용한데, 운영 환경에서는 stdout 스트림 대신 해당 등급 로그에 대한 별도의 출력을 둘 것이다. 이를테면 성능과 관련된 가장 중요한 컴포넌트의 로그는 카프카, 사용자 로그는 일래스틱서치, 그 외의 로그는 아마존 S3 클라우드 스토리지로 보내는 식이다.
