# 14장 업그레이드와 롤백을 이용한 업그레이드 자동화

## 도커를 사용한 애플리케이션 업그레이드 프로세스

애플리케이션에 사용되는 운영체제 업데이트 반영 및 월 단위 업데이트, 애플리케이션에 사용된 라이브러리의 보안 패치를 딱히 정해진 주기 없이 애플리케이션을 업데이트하는데 익숙해져야 한다. 주기적인 배포를 자동화하면 빌드에 신뢰감이 생기고, 다음 배포 주기를 기다리지 않고도 작업이 끝난 새 기능을 바로바로 배포에 포함시킬 수 있다.

### 애플리케이션 배포 주기

* 의존 모듈의 업데이트
* 애플리케이션 코드를 컴파일하는 데 사용하는 SDK 업데이트
* 애플리케이션이 동작하는 플랫폼의 업데이트
* 운영체제 업데이트
* 애플리케이션 버전 업데이트

### 도커 스웜를 통한 스택 배포

* 여러개로 나뉜 컴포즈 파일은 스택 배포에 사용할 수 없으므로 먼저 오버라이드 파일을 하나의 컴포즈 파일로 병합한 후 배포해야 한다.

  ```sh
  # 코어 컴포즈 파일과 어버라이드 파일을 병합한다
  docker-compose -f ./numbers/docker-compose.yml -f ./numbers/prod.yml config > stack.yml
  
  # 병합된 컴포즈 파일로 스택을 배포한다
  docker stack deploy -c stack.yml numbers
  
  # 스택의 서비스 정보를 확인한다
  docker stack services numbers
  ```

### `replicated` 모드 vs `global` 모드

* 서비스는 일반적으로 아무런 설정을 하지 않으면 `replicated` 모드로 실행하는데, 설정을 통해 `global` 모드로 실행할 수 있다.
*  `global` 모드로 동작하는 서비스는 **한 노드에 레플리카를 하나만 실행**하는데, **인그레스 네트워크를 우회하기 위한 목적**으로 사용되며, **리버스 프록시 같은 상황에서 유용**하게 사용할 수 있는 모드다.

```yml
numbers-web:
  ports:
    - target: 80
      published: 80
      mode: host
  deploy:
    mode: global
```

* `global` 모드로 설정하는 부분은 다음 두 필드다.
  * `mode: global` : deploy 항목에 이 필드 설정을 추가하면 해당 서비스는 한 노드에서 한개의 컨테이너만 실행된다. 레플리카의 수는 노드의 수와 같으므로 클러스터에 새로 추가된 노드에도 컨테이너가 실행된다.
  * `mode: host` : ports 항목에 이 필드 설정을 추가하면 해당 서비스를 인그레스 네트워크 대신 호스트의 80번 포트와 연결한다. 한 노드에 레플리카 하나만으로도 무방한 가벼운 웹 애플리케이션이거나 네트워크 성능이 매우 중요해서 인그레스 네트워크 내 라우팅에 따른 오버헤드를 제거하고 싶다면 유용하게 사용할 수 있는 설정 패턴이다.

### 헬스 체크가 포함된 애플리케이션 업데이트

* 서비스 업데이트는 **항상 기존 컨테이너를 종료하고 새 컨테이너를 실행**하는 식의 롤링 업데이트로 이뤄진다.
* 기존 컨테이너가 호스트 컴퓨터의 포트를 계속 연결하고 있는 `global` 모드로 실행된 서비스는 이 방식이 맞고, `replicated` 모드로 실행중인 서비스에서도 이 방식은 이치에 어긋나지 않는다.
* 도커 스웜의 롤링 업데이트는 섬세하게 결정된 기본값을 따라 동작하는데, 레플리카는 하나씩 교체되며 새 컨테이너가 정상적으로 실행되는지 확인이 끝난 후 다음 컨테이너 업데이트에 들어간다. 또 롤링 업데이트는 새 컨테이너를 실행하기 전에 먼저 기존 컨테이너를 종료하는데, 새 컨테이너가 정상적으로 시작되지 않으면 전체 업데이트가 중단된다.
* 롤링 업데이트는 이러한 동작 방식에 이르기까지 세세한 설정 옵션을 제공한다.



## 운영 환경을 위한 롤링 업데이트

도커 스웜의 **롤링 업데이트는 섬세하게 결정된 기본값을 따라 동작**하는데, 레플리카는 하나씩 교체되며 새 컨테이너가 정상적으로 실행되는지 확인이 끝난 후 다음 컨테이너 업데이트에 들어간다. 또 롤링 업데이트는 새 컨테이너를 실행하기 전에 먼저 기존 컨테이너를 종료하는데, 새 컨테이너가 정상적으로 시작되지 않으면 전체 업데이트가 중단된다.

**롤링 업데이트는** 이러한 동작 방식에 이르기까지 **세세한 설정 옵션을 제공**한다.

### 롤링 업데이트 커스텀 설정

```yaml
numbers-api:
  deploy:
    update_config:
      parallelism: 3
      monitor: 60s
      failure_action: rollback
      order: start-first
```

| 필드             | 설명                                                         |
| ---------------- | ------------------------------------------------------------ |
| `parallelism`    | 한 번에 교체하는 레플리카의 수를 의미한다. 기본값은 1이므로 한 번에 레플리카가 하나씩 교체된다. |
| `monitor`        | 다음 컨테이너 교체로 넘어가기 전에 새로 실행한 컨테이너의 이상 여부를 모니터링하는 시간을 의미한다. 기본값은 0이므로 헬스 체크 설정을 포함한 이미지의 경우 이 설정값을 늘려야 한다. 이 시간을 증가시키면 롤링 업데이트의 신뢰성이 증가한다. |
| `failure_action` | `monitor` 에 설정한 시간 이내에 헬스 체크가 실패하거나 컨테이너가 실행되지 않아 롤링 업데이트가 실패한 경우에 어떤 조치를 취해야 하는지를 의미한다. 기본값은 업데이트를 중지한다. |
| `order`          | 레플리카를 교체하는 절차의 순서를 의미한다. `stop-first` 가 기본값으로, 실행 중인 레플리카 수가 서비스 정의에 지정된 숫자를 넘어서지 않는다. 하지만 레플리카를 실행할 수 있는 추가적인 시스템 자원이 있다면 `start-first` 를 선택해 기존 레플리카를 제거하기 전에 새 레플리카를 먼저 검증하도록 하는 것이 좋다. |

> 💡 롤링 업데이트 설정 Tip
>
> * `parallelism` 은 전체 레플리카 수의 30% 정도로 설정하면 롤링 업데이트를 꽤 빠르게 진행할 수 있다.
> * `monitor` 는 헬스 체크가 두세 번 이상 진행될 수 있을 만큼 넉넉한 시간을 지정하는 것이 좋다. 그래야 이번 레플리카 교체가 완전히 끝난 후 다음 레플리카 교체로 들어갈 수 있다.

> 💡 Tip
>
> * 스웜의 서비스 정보에서 서비스 정의, 업데이트 설정, 최근 업데이트 결과 등을 좀 더 쉽게 구분할 수 있는 팁이 있다. `inspect` 명령에서 `pretty` 플래그를 적용하면 된다. 그러면 스택에서 생성된 서비스가 `{stack-name}_{service-name}` 과 같음 형식으로 명명된다.
>
> ```sh
> docker service inspect --pretty numbers_numbers-api
> ```

* 업데이트 설정을 변경할 때 꼭 알아 두어야 할 점은 **이후 배포에도 이들 설정을 포함시켜야 한다**는 것이다. 업데이트하면서 추가한 업데이트 설정은 다음 배포에서도 같은 오버라이드 파일을 사용하지 않으면 원래 업데이트 설정으로 되돌아간다.



## 서비스 롤백 설정하기

롤링 업데이트에 대한 설정과 똑같은 설정을 롤백에도 할 수 있다. 따라서 롤백 시에도 한번에 몇개의 레플리카를 교체할 것인지, 교체된 레플리카를 얼마나 오랫동안 모니터링할 것인지 등을 설정할 수 있다.

### 롤백 커스텀 설정

```yaml
numbers-api:
  deploy:
    rollback_config:
      parallelism: 6
      monitor: 0s
      failure_action: continue
      order: start-first
```

* 이 설정의 목적은 애플리케이션을 가능한 빨리 이전 버전으로 롤백하는 것이다. 따라서 동시 교체 레플리카 수를 6으로 지정해 이상 상태에 있는 레플리카를 한 번에 교체하고, 교체 전략은 `start-first` 를 적용해 기존 레플리카(새 버전) 종료를 신경 쓰지 않고 먼저 새 레플리카(구 버전)를 실행하도록 한다.
* 이 설정은 매우 적극적인 롤백 전략으로 이전 버전에 문제가 없었고 이 버전으로 레플리카를 다시 시작하면 역시 문제가 없으리라 가정해 세운 것이다.
* 롤백이 끝났을 때 서비스 전체 설정을 보면, 롤백 설정이 다시 기본값으로 돌아간 것을 볼 수 있는데, 서비스 설정 전체가 이전으로 돌아가는 것이므로 현재 롤백 과정 자체는 지금의 설정값을 따르지만, 롤백이 끝나고 나면 롤백 설정마저도 이전으로 돌아간다. 그리고 그 다음 업데이트에서 업데이트 설정과 롤백 설정을 다시 한 번 추가해야 기본값으로 업데이트 되지 않는다.

### 도커 컴포즈 파일은 어떻게 분리해야 하나?

* 기본이 되는 컴포즈 파일, 환경별 컴포즈 파일, 헬스 체크 컴포즈 파일, 업데이트 설정 컴포즈 파일, 롤백 설정 컴포즈 파일 등 이렇게 기능별로 도커 컴포즈 파일을 나누게 되면 업데이트 때마다 이들 파일을 빠짐없이 모두 정확한 순서대로 지정해야 하기 때문에 위험하다.
* 일반적으로 코어 컴포즈 파일 하나와 환경별 오버라이드 파일 하나, 버전을 정의하는 파일 정도가 일반적이며, 한 가지 확경의 설정을 굳이 여러 개의 파일로 분리하지는 않는다.

```sh
# 기능별로 분리한 도커 컴포즈 예시
docker-compose -f ./numbers/docker-compose.yml -f ./numbers/prod.yml -f ./numbers/prod-healthcheck.yml -f ./numbers/prod-update-config.yml -f ./numbers/prod-rollback-config.yml -f ./numbers/v5.yml config > stack.yml

# 일반적인 예시
docker-compose -f ./numbers/docker-compose.yml -f ./numbers/prod-full.yml -f ./numbers/v5.yml --log-level ERROR config > stack.yml
```



## 클러스터의 중단 시간

컨테이너 오케스트레이션 도구는 여러 대의 컴퓨터를 묶어 하나의 강력한 클러스터로 만든다. 하지만 결국 실제로 컨테이너를 실행하는 것은 각각의 컴퓨터이므로 중단 시간이 발생할 수 있다. 개개의 컴퓨터의 문제가 생겨도 대부분의 클러스터는 애플리케이션을 그대로 실행할 수 있지만, 그중에는 적극적인 조치가 필요한 경우도 있다. 이러한 조치를 사전에 계획해 둔다면 클러스터가 문제를 비켜가는 데 도움이 된다.

### 사례 1

노드 중 한 대가 운영체제 업데이트 혹은 인프라 작업 등으로 인해 사용할 수 없게 됐다. 이 노드에는 실행 중인 컨테이너가 있을 수도 있어서 이 컨테이너를 안전하게 종료시키고 다른 노드에서 실행한 컨테이너로 교체하고 싶다. 그리고 해당 노드는 유지 보수 모드로 전환해 다음 재부팅 주기가 도래하기 전까지는 이 노드에서 컨테이너를 실행하지 않으려고 한다.

* 스웜에서는 노드의 '유지보수' 모드를 드레인 모드(drain mode)라고 한다. 드레인 모드는 매니저 노드와 워커 노드 모두 설정할 수 있다.

* 워커 노드와 매니저 노드의 드레인 모드는 조금 차이가 있는데, 두 가지 모두 현재 실행 중인 레플리카가 종료되고 새로운 레플리카를 실행하지도 않는다는 점은 같지만, 매니저 노드는 드레인 모드가 돼도 계속 클러스터의 관리 그룹으로 기능하며 클러스터 데이터베이스 동기화 및 관리 API를 제공도 계속하고 매니저 노드 중 리더인 리더 매니저가 될 수도 있다.

  >💡 리더 매니저란?
  >
  >* 고가용성을 확보하려면 매니저 노드가 둘 이상 필요한데, 스웜은 능동-수동 고가용성 모델을 따르기 때문에 클러스터를 실제로 통제하는 매니저는 하나뿐이다. 이 매니저가 바로 리더 매니저다.
  >* 나머지 매니저 노드는 클러스터 데이터베이스의 복본을 유지하며 관리 API 요청을 처리하다가 리더 매니저가 고장을 일으키면 리더 자리를 이어 받는다. 리더 매니저 승계는 남은 매니저 노드끼리 투표를 거쳐 다수결로 결정되는데, 이 때문에 매니저 노드의 수는 항상 홀수여야 한다.
  >* 보통 소규모 클러스터는 세 개, 대규모 클러스터는 다섯 개의 매니저 노드를 갖는다. 매니저 노드 하나를 완전히 상실해 매니저 노드의 수가 짝수가 됐다면 워커 노드 중 하나를 매니저 노드로 승격시킬 수 있다.

```sh
# 워커 노드와 매니저 노드를 하나씩 드레인 모드로 설정한다
docker node update --availability drain node5 # node5는 워커 노드
docker node update --availability drain node3 # node3은 매니저 노드

# 노드 목록 확인
docker node ls

# node1의 터미널에서 - node1이 스웜에서 이탈한다
docker swarm leave --force

# node2의 터미널에서 - node5의 드레인 모드 해제
docker node update --availability active node5

# 워커 노드(node5)를 매니저 노드로 승격
docker node promote node5

# 노드 목록 확인
docker node ls
```

### 사례 2

모든 매니저가 고장을 일으킨 경우

* 매니저 노드가 모두 고장을 일으켜 워커 노드만 남았다면, 애플리케이션은 그대로 잘 실행된다.
* 인그레스 네트워크 및 서비스 레플리카는 워커 노드에서 매니저 노드 없이도 잘 동작하지만, 서비스를 모니터링해 줄 주체가 없기 때문에 서비스 컨테이너가 이상을 일으켜도 컨테이너가 교체되지 않는다. 클러스터를 원 상태로 회복하려면 매니저 노드를 복구해야 한다.

### 사례 3

(리더가 아닌) 한 대를 제외한 모든 매니저 노드가 고장을 일으킨 경우

* 매니저 노드가 한 대 외에는 모두 고장을 일으키고 남은 매니저 노드도 리더 매니저가 아니라면 클러스터의 통제권을 상실할 가능성이 있다. 리더 매니저를 승계하려면 매니저 노드끼리 투표를 해야 하는데, 다른 매니저 노드가 없으니 리더 매니저 승계가 불가능하다.
* 이 상황을 해결하려면 남은 매니저 노드만으로 `swarm init` 명령에 `force-new-cluster` 옵션을 사용해 기존 클러스터의 태스크와 데이터를 그대로 유지하면서 강제로 해당 매니저 노드를 리더 매니저로 만들 수 있다. 그 다음에는 매니저 노드를 추가로 투입해 고가용성을 회복하면 된다.

### 사례 4

노드 간 레플리카를 고르게 재배치하기

* 서비스 레플리카는 클러스터에 노드를 추가해도 알아서 고르게 재배치되지 않는다. 클러스터에 새로 노드를 추가해 처리 용량을 늘렷다 하더라도 서비스를 업데이트하지 않는 한, 새 노드에서는 아무 레플리카도 실행되지 않는다.
* `service update --force` 명령으로 변경 사항 없이 강제로 서비스를 업데이트하면 노드마다 고르게 레플리카를 재배치할 수 있다.



## 스웜 클러스터의 고가용성

애플리케이션의 여러 계층에서 고가용성을 고려할 수 있다.

* 헬스 체크는 애플리케이션 동작 상태를 확인해 이상 상태에 빠진 컨테이너를 새 컨테이너로 교체한다.
* 여러 개의 워커 노드는 노드 중 하나가 고장을 일으켜도 다른 컨테이너를 실행할 능력을 보존한다.
* 여러 개의 매니저 노드는 워커 노드 모니터링 및 컨테이너 배치 능력의 여유분을 확보하는 역할을 한다.

### 데이터센터에 걸쳐 하나의 클러스터를 구성하여 고가용성 확보하기

* 데이터센터에 걸쳐 하나의 클라스터를 구성하여 고가용성을 확보하는 것도 이론적으로는 가능하다. 매니저 노드는 데이터센터 A에 두고, 데이터센터 A, B, C에 워커 노드를 배치할 수도 있다. 이렇게 하면 확실히 클러스터 관리는 단순해질 것이지만 네트워크 지연 시간이라는 문제가 새로 발생한다.
* 만약 지역을 아우르는 거대한 규모의 장애에도 애플리케이션이 계속 동작해야 할 필요가 있다면, 이를 실현할 수 있는 방법은 클러스터를 여러 개 구성하는 것뿐이다. 관리적 측면으로는 오버헤드가 발생하고 애플리케이션이 서로 다른 클러스터로 떠다닐 우려가 있지만, 네트워크 지연과 달리 이 정도 문제는 충분히 통제할 수 있다.

