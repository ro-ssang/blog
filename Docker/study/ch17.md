# 17장 도커 이미지 최적화하기: 보안, 용량 속도

## 도커 이미지를 최적화하는 방법

### 사용하지 않는 도커 리소스 제거하기

이미지끼리 레이어를 공유하기 때문에 도커 이미지는 이미 최적화가 상당히 잘된 포멧이다. 하지만 도커는 데이터를 보수적으로 다루는데, **내려받은 이미지는 명시적으로 삭제하지 않는 한 자동으로 삭제되지 않는다**. 그러다 보니 디스크 용량이 순식간에 잠식되는 경우가 많다. 따라서 주기적으로 `docker system prune` 명령어를 실행해 사용하지 않는 이미지 레이어나 빌드 캐시를 비워 주는 것이 좋다.

```sh
# 이미지와 컨테이너, 볼륨, 빌드 캐시 등이 점유하는 실제 디스크 용량 확인
docker system df

# 사용하지 않는 이미지 레이어나 빌드 캐시 제거
docker system prune
```

### 이미지 레이어 최적화하기

Dockerfile에서는 스크립트의 인스트럭션 하나마다 이미지 레이어가 하나씩 생기고 이 레이어가 모두 합쳐져 전체 이미지가 된다. 만약 특정 레이어에서 파일을 복사하고 그 다음 레이어에서 지우더라도 파일 시스템에서 숨겨질 뿐 실제로 파일이 삭제되지는 않기 때문에 한 번 이미지에 복사된 파일은 이미지에서 뺄 수 없다. 따라서 이미지를 최적화하려면 **꼭 필요한 파일만 이미지에 포함**시켜야 한다.

또한 도커의 빌드 과정은 엔진에 빌드 컨텍스트(빌드를 실행한 디렉터리)를 압축하고 Dockerfile 스크립트를 함께 보내면서 시작되는데, 이 빌드 컨텍스트에는 불피요한 파일이 포함되는 경우가 많다. 따라서 **.dockerignore 파일에 불필요한 디랙터리나 파일 목록을 기재하면 빌드 컨텍스트에서 이들 파일을 제외할 수 있다**.

```sh
# .dockerignore 파일
docs/
Dockerfile*
```




## 좋은 기반 이미지를 고르는 법

기반 이미지의 크기는 디스크 용량이나 네트워크 전송 시간뿐만 아니라 애플리케이션 보안과도 관계가 깊다.

운영체제 기반 이미지의 크기가 크면 다양한 도구가 포함되기 마련인데, 예를 들어 운영체제 기반 이미지에 curl이 설치돼 있다면, 애플리케이션 컨테이너에 침입한 공격자가 curl을 이용해 악의적인 소프트웨어를 컨테이너로 내려받거나 자신의 서버로 데이터를 전송할 수도 있다. 따라서 기반 이미지에는 **크기가 작은 변종 이미지부터 검토**하는 것이 좋다.

애플리케이션 플랫폼 기반 이미지라도 마찬가지이며, 공격자의 악의적인 행동을 방지하기 위해 **이미지 최종 결과물에 빌드에 필요한 도구를 포함시켜서는 안된다**. (단, Node.js나 파이썬 같은 인터프리터 언어는 빌드 도구가 애플리케이션 실행에도 사용되므로 여기에 해당되지 않는다.)

각 운영체제제마다 가장 작은 크기의 이미지에 기반을 둔 다중 아키텍처 이미지를 만들어 **골든 이미지로 사용**하는 것도 이러한 문제를 피할 수 있는 한 가지 방법이다. 직접 만든 골든 이미지는 업데이트 주기를 스스로 결정할 수 있꼬 골든 이미지 빌드 후에 바로 이어서 애플리케이션 빌드를 진행할 수 있다. 또한, **앤코어(Ancore) 같은 서드파티 도구를 골든 이미지에 삽입해 빌드 중에 보안 검사**를 할 수 있다는 것도 장점이다.

### 앤코어 사용 방법

```yaml
# 앤코어 docker-compose 파일

version: '2.1'
volumes:
  anchore-db-volume:
    # Set this to 'true' to use an external volume. In which case, it must be created manually with "docker volume create anchore-db-volume"
    external: false

  anchore-scratch: {}

services:
  # The primary API endpoint service
  engine-api:
    image: anchore/anchore-engine:v0.5.2
    depends_on:
    - anchore-db
    - engine-catalog
    #volumes:
    #- ./config-engine.yaml:/config/config.yaml:z
    ports:
    - "8228:8228"
    logging:
      driver: "json-file"
      options:
        max-size: 100m
    environment:
    - ANCHORE_ENDPOINT_HOSTNAME=engine-api
    - ANCHORE_DB_HOST=anchore-db
    - ANCHORE_DB_PASSWORD=mysecretpassword
    - ANCHORE_LOG_LEVEL=INFO
    command: ["anchore-manager", "service", "start", "apiext"]

  # Catalog is the primary persistence and state manager of the system
  engine-catalog:
    image: anchore/anchore-engine:v0.5.2
    depends_on:
    - anchore-db
    #volumes:
    #- ./config-engine.yaml:/config/config.yaml:z
    logging:
      driver: "json-file"
      options:
        max-size: 100m
    expose:
    - 8228
    environment:
    - ANCHORE_ENDPOINT_HOSTNAME=engine-catalog
    - ANCHORE_DB_HOST=anchore-db
    - ANCHORE_DB_PASSWORD=mysecretpassword
    - ANCHORE_LOG_LEVEL=INFO
    command: ["anchore-manager", "service", "start", "catalog"]
  engine-simpleq:
    image: anchore/anchore-engine:v0.5.2
    depends_on:
    - anchore-db
    - engine-catalog
    #volumes:
    #- ./config-engine.yaml:/config/config.yaml:z
    expose:
    - 8228
    logging:
      driver: "json-file"
      options:
        max-size: 100m
    environment:
    - ANCHORE_ENDPOINT_HOSTNAME=engine-simpleq
    - ANCHORE_DB_HOST=anchore-db
    - ANCHORE_DB_PASSWORD=mysecretpassword
    - ANCHORE_LOG_LEVEL=INFO
    command: ["anchore-manager", "service", "start", "simplequeue"]
  engine-policy-engine:
    image: anchore/anchore-engine:v0.5.2
    depends_on:
    - anchore-db
    - engine-catalog
    #volumes:
    #- ./config-engine.yaml:/config/config.yaml:z
    expose:
    - 8228
    logging:
      driver: "json-file"
      options:
        max-size: 100m
    environment:
    - ANCHORE_ENDPOINT_HOSTNAME=engine-policy-engine
    - ANCHORE_DB_HOST=anchore-db
    - ANCHORE_DB_PASSWORD=mysecretpassword
    - ANCHORE_LOG_LEVEL=INFO
    command: ["anchore-manager", "service", "start", "policy_engine"]
  engine-analyzer:
    image: anchore/anchore-engine:v0.5.2
    depends_on:
    - anchore-db
    - engine-catalog
    #volumes:
    #- ./config-engine.yaml:/config/config.yaml:z
    expose:
    - 8228
    logging:
      driver: "json-file"
      options:
        max-size: 100m
    environment:
    - ANCHORE_ENDPOINT_HOSTNAME=engine-analyzer
    - ANCHORE_DB_HOST=anchore-db
    - ANCHORE_DB_PASSWORD=mysecretpassword
    - ANCHORE_LOG_LEVEL=INFO
    volumes:
    - anchore-scratch:/analysis_scratch
    command: ["anchore-manager", "service", "start", "analyzer"]
  anchore-db:
    image: "postgres:9"
    volumes:
    - anchore-db-volume:/var/lib/postgresql/data
    environment:
    - POSTGRES_PASSWORD=mysecretpassword
    expose:
    - 5432
    logging:
      driver: "json-file"
      options:
        max-size: 100m
  # Kubernetes handler webhook. Uncomment to use, not typically needed for docker-compose installs
#  kubehook:
#    image: anchore/anchore-engine:v0.5.2
#    depends_on:
#    - anchore-db
#    - engine-catalog
#    ports:
#    - "8338:8228"
#    logging:
#      driver: "json-file"
#      options:
#        max-size: 100m
#    environment:
#    - ANCHORE_DB_HOST=anchore-db
#    - ANCHORE_DB_PASSWORD=mysecretpassword
#    - ANCHORE_ENDPOINT_HOSTNAME=kubehook
#    command: ["anchore-manager", "service", "start", "kubernetes_webhook"]
```

```sh
# 앤코어의 모든 구성 요소를 실행한다
docker-compose up -d

# 앤코어가 데이터베이스를 내려받는 데 15분 정도가 걸린다
docker exec anchore_engine-api_1 anchore-cli system wait

# 자바 골든 이미지 Dockerfile 스크립트를 컨테이너로 복사한다
docker container cp "$(pwd)/../../../images/openjdk/Dockerfile" anchore_engine-api_1/Dockerfile

# 이미지와 Dockerfile을 앤코어로 분석한다.
docker container exec anchore_engine-api_1 anchore-cli image add diamol/openjdk --dockerfile /Dockerfile

# 분석 결과를 기다린다
docker container exec anchore_engine-api_1 anchore-cli image wait diamol/openjdk

# 이미지에서 사용된 자바 컴포넌트를 확인한다
docker container exec anchore_engine-api_1 anchore-cli image content diamol/openjdk java

# 이미지에서 발견된 보안 취약점을 확인한다
docker container exec anchore_engine-api-1 anchore-cli image vuln diamol/openjdk all
```

이미지에 사용된 오픈 소스 소프트웨어의 라이선스부터 운영체제와 애플리케이션 플랫폼에 대한 상세 정보, 이미지에 포함된 바이너리 파일의 보안 문제까지 앤코어 분석이 끝나면 이미지에 포함된 다양하고 많은 문제점을 지적해 준다. 이렇게 발견된 문제점으로 업데이트된 기반 이미지의 품질을 평가할 수도 있어 회사에서 사용할 수 없는 오픈소스 라이선스가 적용됐거나 심각한 취약점을 포함하고 있다면, 해당 업데이트는 적용하지 않으면 된다.

또한 앤코어는 젠킨스 같은 CI/CD 도구용 플러그인을 제공하므로 이를 사용해 원하는 정책을 파이프라인에 포함시킬 수 있다. 분석 결과는 앤코어 API 컨테이너에 직접 쿼리로 문의할 수 있다.



## 이미지 레이어 수와 이미지 크기는 최소한으로

최소한의 크기와 보안성을 갖춘 기반 이미지는 애플리케이션 이미지 최적화의 전제 조건이다. 소프트웨어를 설치하면 패키지 목록을 캐싱하거나 추천 패키지 등을 함께 설치하기 때문에 대부분의 경우 불필요한 요소나 설치 후 잔재가 발생한다. 따라서 이런 요소까지 확실하게 통제할 수 있어야 한다.

```dockerfile
# 일반적인 방식으로 APT를 사용함
FROM debian:stretch-slim

RUN apt-get update
RUN apt-get install -y curl=7.52.1-5+deb9u16
RUN apt-get install -y socat=1.7.3.1-2+deb9u1

# 패키지 설치 과정을 최적화함
FROM debian:stretch-slim

RUN apt-get update \
 && apt-get install -y --no-install-recommends \ # 추천하는 패키지를 설치하지 않음
    curl=7.52.1-5+deb9u16 \
    socat=1.7.3.1-2+deb9u1 \
 && rm -rf /var/lib/apt/lists/* # 설치 후 패키지 목록 캐싱 삭제
```

인터넷에서 압축된 패키지를 내려받아 압축을 해제한 후 설치하는 경우, **다운로드-압축 해제-삭제까지의 단계를 모두 하나의 인스트럭션에서 수행하도록 하는 것이 좋다**. 압축의 경우 디스크 용량이 가장 많이 절약되는 부분은 압축 파일을 삭제해서가 아니라 필요한 파일만 압축을 해제하기 때문이다.

```dockerfile
FROM diamol/base

ARG DATASET_URL=https://archive.ics.uci.edu/ml/machine-learning-databases/url/url_svmlight.tar.gz

WORKDIR /dataset

RUN wget -O dataset.tar.gz ${DATASET_URL} && \
    tar -xf dataset.tar.gz url_svmlight/Day1.svm && \
    rm -f dataset.tar.gz
```



## 멀티 스테이지 빌드를 한 단계 업그레이드하기

개발 업무의 편의를 유지하면서도 이미지도 함께 최적화할 수 있는 다른 방법이 있는데, 파일을 다루는 단계를 모두 스테이지로 분리해 디스크 용량을 절약하는 **멀티 스테이지 빌드**다.

```dockerfile
# 멀티 스테이지 - 압축 파일 예시
FROM diamol/base AS download
ARG DATASET_URL=https://archive.ics.uci.edu/ml/machine-learning-databases/url/url_svmlight.tar.gz
RUN wget -O dataset.tar.gz ${DATASET_URL}

FROM diamol/base AS expand
COPY --from=download dataset.tar.gz .
RUN tar xvzf dataset.tar.gz

FROM diamol/base
WORKDIR /dataset/url_svmlight
COPY --from=expand url_svmlight/Day1.svm .
```

```dockerfile
# 멀티 스테이지 사용하지 않은 경우 - 젠킨스 예시
FROM diamol/base

ENV JENKINS_HOME="/data" \
    JENKINS_VERSION="2.190.2"

COPY ./jenkins.install.UpgradeWizard.state ${JENKINS_HOME}/

WORKDIR /jenkins
RUN wget -O jenkins.war https://mirrors.jenkins.io/war-stable/${JENKINS_VERSION}/jenkins.war

EXPOSE 8080
ENTRYPOINT java -Duser.home=${JENKINS_HOME} -Djenkins.install.runSetupWizard=false -jar /jenkins/jenkins.war

# 멀티 스테이지 - 젠킨스 예시 : 멀티 스테이지를 사용함으로써 설정 파일을 수정해도 배포 파일을 다시 내려 받지 않을 수 있다.
FROM diamol/base AS download
ARG JENKINS_VERSION="2.190.2"
RUN wget -O jenkins.war http://mirrors.jenkins.io/war-stable/${JENKINS_VERSION}/jenkins.war

FROM diamol/base
ENV JENKINS_HOME="/data"
EXPOSE 8080
ENTRYPOINT java -Duser.home=${JENKINS_HOME} -Djenkins.install.runSetupWizard=false -jar /jenkins/jenkins.war
COPY --from=download jenkins.war /jenkins/jenkins.war
COPY ./jenkins.install.UpgradeWizard.state ${JENKINS_HOME}/
```



## 최적화가 중요한 이유

### Dockerfile 스크립트 최적화하는 방법 정리

* 기반 이미지 잘 고르기, 자신만의 골든 이미지를 갖출 수 있다면 이상적이다.
* 아주 간단한 애플리케이션이 아니라면 멀티 스테이지 빌드를 적용한다.
* 불필요한 패키지나 파일을 포함시키지 말고, 레이어 크기를 최소한으로 유지한다.
* Dockerfile 스크립트의 인스트럭션은 자주 수정하는 순서대로 뒤에 오도록 배치해 캐시를 최대한 활용한다.
